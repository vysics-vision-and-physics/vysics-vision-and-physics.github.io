<html>
<head>

    <meta charset="utf-8" />
    <title>Vysics</title>

    <meta content="Vysics combines computer vision and contact-rich physics to perform shape reconstruction under occlusion from short RGBD videos and robot proprioception."
        name="description" />
    <meta content="Vysics combines vision and physics for shape reconstruction." property="og:title" />
    <meta content="Vysics combines computer vision and contact-rich physics to perform shape reconstruction under occlusion from short RGBD videos and robot proprioception."
        name="description"
        property="og:description" />
    <meta content="https://vysics-vision-and-physics.github.io/static/images/meta.png" property="og:image" />
    <meta content="Vysics combines vision and physics for shape reconstruction." property="twitter:title" />
    <meta content="Vysics combines computer vision and contact-rich physics to perform shape reconstruction under occlusion from short RGBD videos and robot proprioception."
        name="description"
        property="twitter:description" />
    <meta content="https://vysics-vision-and-physics.github.io/static/images/meta.png" property="twitter:image" />
    <meta property="og:type" content="website" />
    <meta content="summary_large_image" name="twitter:card" />
    <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />


    <link href="https://fonts.googleapis.com" rel="preconnect" />
    <link href="https://fonts.gstatic.com" rel="preconnect"
        crossorigin="anonymous" />
    <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js"
        type="text/javascript"></script>
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
    <script type="text/javascript">WebFont.load({google: {families: [
        "Lato:100,100italic,300,300italic,400,400italic,700,700italic,900,900italic",
        "Montserrat:100,100italic,200,200italic,300,300italic,400,400italic,500,500italic,600,600italic,700,700italic,800,800italic,900,900italic",
        "Ubuntu:300,300italic,400,400italic,500,500italic,700,700italic",
        "Open Sans:300,300italic,400,400italic,600,600italic,700,700italic,800,800italic",
        "Changa One:400,400italic",
        "Varela Round:400",
        "Bungee Shade:regular",
        "Roboto:300,regular,500",
        "Bungee Outline:regular"] } });
    </script>

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1/jquery.min.js">
    </script>
    <script src="script.js" type="text/javascript"></script>

    <link href="style.css" rel="stylesheet" type="text/css" />

    <link href="./static/images/favicon.png" rel="shortcut icon"
        type="image/x-icon" />

    <link rel="stylesheet"
        href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

<!--     <script>
        // Check if the user is on a mobile device or the window width is 800px or less.
        if (window.innerWidth <= 800 || /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)) {
            window.location.href = "mobile.html";  // Redirect to mobile version
        }
    </script> -->
</head>

<body>
    <div class="section">
        <div class="container">
            <br>
            <h1 class="title">Vysics</h1>
            <h1 class="subheader">Object Reconstruction Under Occlusion by
                Fusing Vision and Contact-Rich Physics</h1>

            <div class="publication-authors" style="font-size:1.25rem;">
                <span class="author-block">
                    <a href="http://www.bianchini-love.com/bibit"
                        target="_blank">Bibit Bianchini</a><sup>*1</sup>,</span>
                <span class="author-block">
                    <a href="https://scholar.google.com/citations?user=70CbUXwAAAAJ&hl=en"
                        target="_blank">Minghan Zhu</a><sup>*1</sup>,</span>
                <span class="author-block">
                    <a href="https://scholar.google.com/citations?user=hXb_RHoAAAAJ&hl=en"
                        target="_blank">Mengti Sun</a><sup>2</sup>,</span>
                <span class="author-block">
                    <a href="https://scholar.google.com/citations?user=_6AHV9QAAAAJ&hl=en"
                        target="_blank">Bowen Jiang</a><sup>1</sup>,</span>
                <span class="author-block">
                    <a href="https://www.cis.upenn.edu/~cjtaylor/"
                        target="_blank">Camillo J. Taylor</a><sup>1</sup>,</span>
                <span class="author-block">
                    <a href="https://www.grasp.upenn.edu/people/michael-posa/"
                        target="_blank">Michael Posa</a><sup>1</sup></span>
            </div>
            <br>
            <div class="publication-authors"
                style="font-size:1.25rem; line-height:22px;">
                <span class="author-block" style="display:block"><sup>*</sup>The
                    first two authors contributed equally to this work.</span>

                <span class="author-block" style="display:block"><sup>
                    1</sup>University of Pennsylvania </span>

                <span class="author-block" style="display:block"><sup>
                    2</sup>Amazon</span>

                <span class="author-block"
                    style="display:block; line-height:60px;">Robotics: Science
                    and Systems (RSS), 2025</span>
            </div>
            <br>

            <div class="link-labels base-row">
                <!-- TODO: Update arxiv link -->
                <div class="base-col icon-col">
                    <!-- <a href="https://arxiv.org/abs/2410.23643" target="_blank"
                        class="link-block"> -->
                    <img src="https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/5cab99df4998decfbf9e218e_paper-01.png"
                        alt="paper"
                        sizes="(max-width: 479px) 12vw, (max-width: 767px) 7vw, (max-width: 991px) 41.8515625px, 56.6953125px"
                        srcset="https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/5cab99df4998decfbf9e218e_paper-01-p-500.png 500w, https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/5cab99df4998decfbf9e218e_paper-01.png 672w"
                        class="icon-img" />
                    </a>
                </div>
                <!-- TODO: Update code link -->
                <div class="base-col icon-col">
                    <!-- <a href="https://github.com/ebianchi/bundlenets/tree/structural-changes"
                        target="_blank" > -->
                    <img src="https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/5cae3b53b42ebb3dd4175a82_68747470733a2f2f7777772e69636f6e66696e6465722e636f6d2f646174612f69636f6e732f6f637469636f6e732f313032342f6d61726b2d6769746875622d3235362e706e67.png"
                        alt="code" class="icon-img github-img-icon" />
                    </a>
                </div>
                <!-- TODO: Update dataset link -->
                <div class="base-col icon-col">
                    <!-- <a href="https://github.com/ebianchi/bundlenets/tree/structural-changes"
                        target="_blank" > -->
                    <img src="./static/logos/dataset_icon.png"
                        alt="code" class="icon-img github-img-icon" />
                    </a>
                </div>
                <!-- TODO: Update Youtube link -->
                <div class="column-2 base-col icon-col">
                    <!-- <a href="https://youtu.be/Tuzhn4HWiL0" target="_blank"
                        class="link-block"> -->
                    <img src="./static/logos/youtube_1.svg"
                        alt="video" class="icon-img data-img-icon" />
                    </a>
                </div>
            </div>
            <div class="link-labels base-row">
                <div class="base-col icon-col">
                    <strong class="link-labels-text">Paper<br>(coming soon)</strong>
                </div>
                <div class="base-col icon-col">
                    <strong class="link-labels-text">Code<br>(coming soon)</strong>
                </div>
                <div class="base-col icon-col">
                    <strong class="link-labels-text">Dataset<br>(coming soon)</strong>
                </div>
                <div class="base-col icon-col">
                    <strong class="link-labels-text">Video<br>(coming soon)</strong>
                </div>
            </div>

            <br>

            <!-- Main video -->
            <div class="base-row add-top-padding">
                <video id="main-video" autobuffer muted autoplay loop>
                    <source id="mp4"
                        src="./static/images/vysics_intro_overlay_small.mp4"
                        type="video/mp4">
                </video>
            </div>

            <h1 class="tldr">
                <b>TL;DR</b>:
                <u>Vysics</u> is a vision-and-physics framework for a robot to
                build an expressive geometry and dynamics model of a single
                rigid body, using a seconds-long RGBD video and the robot's
                proprioception.
            </h1>

            <br>

            <!-- Abstract -->
            <div class="base-row add-top-padding">
                <h1 id="abstract">Abstract</h1>
                <p class="paragraph">
                    We introduce <b>Vysics</b>, a vision-and-physics framework
                    for a robot to build an expressive geometry and dynamics
                    model of a single rigid body, using a seconds-long RGBD
                    video and the robot's proprioception. While the computer
                    vision community has built powerful visual 3D perception
                    algorithms, cluttered environments with heavy occlusions can
                    limit the visibility of objects of interest. However,
                    observed motion of partially occluded objects can imply
                    physical interactions took place, such as contact with a
                    robot or the environment. These inferred contacts can
                    supplement the visible geometry with “physible geometry,”
                    which best explains the observed object motion through
                    physics. Vysics uses a vision-based tracking and
                    reconstruction method, BundleSDF, to estimate the trajectory
                    and the visible geometry from an RGBD video, and an
                    odometry-based model learning method, Physics Learning
                    Library (PLL), to infer the “physible” geometry from the
                    trajectory through implicit contact dynamics optimization.
                    The visible and “physible” geometries jointly factor into
                    optimizing a signed distance function (SDF) to represent the
                    object shape. Vysics does not require pretraining, nor
                    tactile or force sensors. Compared with vision-only methods,
                    Vysics yields object models with higher geometric accuracy
                    and better dynamics prediction in experiments where the
                    object interacts with the robot and the environment under
                    heavy occlusion.
                </p>
            </div>

            <br>

            <!-- Architecture -->
            <div class="base-row add-top-padding">
                <h1 id="abstract">Architecture</h1>
                <video id="arch-video" autoplay muted loop playsinline
                    height="100%">
                    <source
                        src="./static/images/vysics_architecture_animation.mp4"
                        type="video/mp4">
                </video>
                <p class="paragraph">
                    The figure illustrates the overall design of <b>Vysics</b>
                    from input RGBD videos and robot states (left) to URDF
                    output (right). Its core components are
                    <!-- TODO:  link to BundleSDF? -->
                    <!-- <a href="https://bundlesdf.github.io/" target="_blank">BundleSDF</a> -->
                    BundleSDF for vision-based tracking and shape
                    reconstruction, and PLL for physics-inspired dynamics
                    learning. Beyond the insights that led to this systems
                    integration, our main contribution lies in how Vysics
                    incorporates these two powerful tools together such that
                    they supervise each other and output an object dynamics
                    model, featuring geometry informed by both vision and
                    contact.
                </p>
            </div>

            <br>

            <!-- Geometry results -->
            <div class="base-row add-top-padding">
                <h1 id="abstract">Geometry Results</h1>
                
                <nav>
                    <div class="carousel-slider-wrapper">
                        <div class = "carousel-slider">

                            <div class="video-container">
                                <video autoplay controls muted loop playsinline
                                    height="100%">
                                    <source
                                        src="./static/images/carousel_geometry/geometry_milk_3_small.mp4"
                                        type="video/mp4">
                                </video>
                            </div>

                            <div class="video-container">
                                <video autoplay controls muted loop playsinline
                                    height="100%">
                                    <source
                                        src="./static/images/carousel_geometry/geometry_oatly_11_small.mp4"
                                        type="video/mp4">
                                </video>
                            </div>

                            <div class="video-container">
                                <video autoplay controls muted loop playsinline
                                    height="100%">
                                    <source
                                        src="./static/images/carousel_geometry/geometry_styrofoam_1_small.mp4"
                                        type="video/mp4">
                                </video>
                            </div>

                            <div class="video-container">
                                <video autoplay controls muted loop playsinline
                                    height="100%">
                                    <source
                                        src="./static/images/carousel_geometry/geometry_egg_6_small.mp4"
                                        type="video/mp4">
                                </video>
                            </div>

                            <div class="video-container">
                                <video autoplay controls muted loop playsinline
                                    height="100%">
                                    <source
                                        src="./static/images/carousel_geometry/geometry_bottle_1_small.mp4"
                                        type="video/mp4">
                                </video>
                            </div>

                            <div class="video-container">
                                <video autoplay controls muted loop playsinline
                                    height="100%">
                                    <source
                                        src="./static/images/carousel_geometry/geometry_toblerone_11_small.mp4"
                                        type="video/mp4">
                                </video>
                            </div>

                            <div class="video-container">
                                <video autoplay controls muted loop playsinline
                                    height="100%">
                                    <source
                                        src="./static/images/carousel_geometry/geometry_bakingbox_3_small.mp4"
                                        type="video/mp4">
                                </video>
                            </div>

                            <div class="video-container">
                                <video autoplay controls muted loop playsinline
                                    height="100%">
                                    <source
                                        src="./static/images/carousel_geometry/geometry_milk_8_small.mp4"
                                        type="video/mp4">
                                </video>
                            </div>

                            <div class="video-container">
                                <video autoplay controls muted loop playsinline
                                    height="100%">
                                    <source
                                        src="./static/images/carousel_geometry/geometry_oatly_6_small.mp4"
                                        type="video/mp4">
                                </video>
                            </div>
                        </div>
                        <button class="carousel-button left" type="button">&lt;</button>
                        <button class="carousel-button right" type="button">&gt;</button>
                    </div>
                </nav>
                <div class="columns is-centered" style="margin-top: -60px;">
                    <div class="column is-1">
                        <img src="./static/images/error_bar_text.png" alt="errorbar" style="display: block; margin: 0 auto; width: 60%; margin-bottom: 10px;">
                    </div>
                </div>
                <p class="paragraph">
                    Vysics trains on a seconds-long RGBD video and the robot's
                    proprioception.  Each example above shows the input video,
                    a photo of the object, and the reconstructed geometry from
                    Vysics (which fuses vision and physics) and BundleSDF (vision-only).  
                </p>

                <nav>
                    <div class="carousel-slider-wrapper">
                        <div class = "carousel-slider">

                            <div class="video-container">
                                <video autoplay controls muted loop playsinline
                                    height="100%">
                                    <source
                                        src="./static/images/carousel_overlay/overlay_milk_3_small.mp4"
                                        type="video/mp4">
                                </video>
                            </div>

                            <div class="video-container">
                                <video autoplay controls muted loop playsinline
                                    height="100%">
                                    <source
                                        src="./static/images/carousel_overlay/overlay_oatly_11_small.mp4"
                                        type="video/mp4">
                                </video>
                            </div>

                            <div class="video-container">
                                <video autoplay controls muted loop playsinline
                                    height="100%">
                                    <source
                                        src="./static/images/carousel_overlay/overlay_styrofoam_1_small.mp4"
                                        type="video/mp4">
                                </video>
                            </div>

                            <div class="video-container">
                                <video autoplay controls muted loop playsinline
                                    height="100%">
                                    <source
                                        src="./static/images/carousel_overlay/overlay_egg_6_small.mp4"
                                        type="video/mp4">
                                </video>
                            </div>

                            <div class="video-container">
                                <video autoplay controls muted loop playsinline
                                    height="100%">
                                    <source
                                        src="./static/images/carousel_overlay/overlay_bottle_1_small.mp4"
                                        type="video/mp4">
                                </video>
                            </div>

                            <div class="video-container">
                                <video autoplay controls muted loop playsinline
                                    height="100%">
                                    <source
                                        src="./static/images/carousel_overlay/overlay_toblerone_11_small.mp4"
                                        type="video/mp4">
                                </video>
                            </div>

                            <div class="video-container">
                                <video autoplay controls muted loop playsinline
                                    height="100%">
                                    <source
                                        src="./static/images/carousel_overlay/overlay_bakingbox_3_small.mp4"
                                        type="video/mp4">
                                </video>
                            </div>

                            <div class="video-container">
                                <video autoplay controls muted loop playsinline
                                    height="100%">
                                    <source
                                        src="./static/images/carousel_overlay/overlay_milk_8_small.mp4"
                                        type="video/mp4">
                                </video>
                            </div>

                            <div class="video-container">
                                <video autoplay controls muted loop playsinline
                                    height="100%">
                                    <source
                                        src="./static/images/carousel_overlay/overlay_oatly_6_small.mp4"
                                        type="video/mp4">
                                </video>
                            </div>
                        </div>
                        <button class="carousel-button left" type="button">&lt;</button>
                        <button class="carousel-button right" type="button">&gt;</button>
                    </div>
                </nav>

                <p class="paragraph">
                    Above, see the learned geometries overlaid on the input
                    video, located at the BundleSDF tracked pose.  This shows
                    how the physics-based reasoning helps to extend the geometry
                    beyond the visible regions, towards contacts PLL infers from
                    the trajectory.  The end effector is highlighted in yellow.
                    <br><br>
                    These videos occasionally show imperfections in the pose
                    estimates from BundleSDF.  Vysics is robust to these amounts
                    of pose jittering since its contact estimates from PLL
                    utilize a smooth, implicit-based loss designed with the
                    multi-modal nature of contact in mind.  However Vysics
                    cannot recover from large pose errors, since this prevents
                    consistent incorporation of temporally estimated contacts
                    into a single object model.
                </p>

                <div class="columns is-centered">
                    <div class="column">
                        <img id="geometry-img"
                            src="./static/images/geometry_chamfer.png" />
                    </div>
                    <div class="column">
                        <img id="geometry-img"
                            src="./static/images/geometry_iou.png" />
                    </div>
                </div>

                <p class="paragraph">
                    Due to severe occlusion in the RGBD videos, vision-based
                    reconstruction yields significant errors.  For every example
                    in our dataset, our method improves the reconstructed
                    geometry by recovering the occluded geometry through
                    physics-based reasoning over the observed trajectories.
                    The plots above show substantial and consistent improvements
                    in terms of both the surface-based metric (chamfer distance)
                    and the volume-based metric (IoU).
                </p>
            </div>

            <br>

            <!-- Geometry comparison to data-driven 3d generative models -->
            <div class="base-row add-top-padding">
                <h1>Geometry Comparison to Data-Driven 3D Generative Models</h1>
                <p class="paragraph">
                    While the objects are heavily occluded in the camera view,
                    one may wonder if 3D foundation models, which learn prior
                    knowledge of the shape of typical objects from a large
                    amount of data, may recover the occluded geometry in a
                    generative way.  We tested several data-driven 3D generative
                    models:  <a
                    href="https://ieeexplore.ieee.org/document/10160350">
                    3DSGrasp</a> for point cloud completion (we use points from
                    visible mesh faces reconstructed by BundleSDF as input);
                    <a href="https://yushuang-wu.github.io/IPoD/">IPoD</a> for
                    single-object completion from an RGBD image; and <a
                    href="https://herb-wright.github.io/v-prism/">V-PRISM</a>
                    and <a href="https://sh8.io/#/oct_mae">OctMAE</a> for
                    multi-object scene completion from an RGBD image.  All of
                    these methods, like Vysics and BundleSDF, are
                    category-agnostic.  For reconstruction methods from a single
                    image, we use the last frame of each video clip, which, in
                    our data, is typically less occluded. We provide object
                    masks for IPoD and foreground masks for V-PRISM and OctMAE,
                    then segment the object from their scene completion outputs.
                    We use published pretrained models for evaluation.  See the
                    below table for results, showing Vysics outperforms all
                    other baselines for each object in our dataset and overall.
                    Foundation models are not yet a hand-waving solution to
                    shape reconstruction under occlusion, but it could be
                    valuable to incorporate a data-based prior in our framework
                    in the future.
                </p>

                <h2>Table 1:  Chamfer Distance (cm)</h2>
                <table>
                    <thead>
                      <tr>
                        <th>Method</th>
                        <th>bakingbox</th>
                        <th>bottle</th>
                        <th>egg</th>
                        <th>milk</th>
                        <th>oatly</th>
                        <th>styrofoam</th>
                        <th>toblerone</th>
                        <th>all</th>
                      </tr>
                    </thead>
                    <tbody>
                      <tr>
                        <td><a href="https://bundlesdf.github.io">BundleSDF
                            </a></td>
                        <td>3.84</td>
                        <td>2.65</td>
                        <td>3.70</td>
                        <td>3.17</td>
                        <td>2.45</td>
                        <td>2.55</td>
                        <td>2.44</td>
                        <td>2.98</td>
                      </tr>
                      <tr>
                        <td><a
                            href="https://ieeexplore.ieee.org/document/10160350">
                            3DSGrasp</a></td>
                        <td>3.83</td>
                        <td>2.80</td>
                        <td>3.78</td>
                        <td>3.15</td>
                        <td>2.51</td>
                        <td>2.66</td>
                        <td>2.77</td>
                        <td>3.06</td>
                      </tr>
                      <tr>
                        <td><a href="https://yushuang-wu.github.io/IPoD/">IPoD
                            </a></td>
                        <td>3.25</td>
                        <td>1.80</td>
                        <td>2.16</td>
                        <td>2.37</td>
                        <td>2.73</td>
                        <td>1.93</td>
                        <td>1.97</td>
                        <td>2.47</td>
                      </tr>
                      <tr>
                        <td><a href="https://herb-wright.github.io/v-prism/">
                            V-PRISM</a></td>
                        <td>3.52</td>
                        <td>2.47</td>
                        <td>2.31</td>
                        <td>3.33</td>
                        <td>2.30</td>
                        <td>2.54</td>
                        <td>2.48</td>
                        <td>2.80</td>
                      </tr>
                      <tr>
                        <td><a href="https://sh8.io/#/oct_mae">OctMAE</a></td>
                        <td>3.11</td>
                        <td>2.22</td>
                        <td>1.52</td>
                        <td>2.93</td>
                        <td>2.13</td>
                        <td>2.00</td>
                        <td>2.36</td>
                        <td>2.45</td>
                      </tr>
                      <tr>
                        <td>Vysics (ours)</td>
                        <td>1.83</td>
                        <td>1.36</td>
                        <td>1.05</td>
                        <td>1.53</td>
                        <td>1.25</td>
                        <td>1.45</td>
                        <td>1.02</td>
                        <td>1.45</td>
                      </tr>
                    </tbody>
                </table>
            </div>

            <br>

            <!-- Dynamics predictions -->
            <div class="base-row add-top-padding">
                <h1 id="abstract">Dynamics Predictions</h1>
                <nav>
                    <div class="carousel-slider-wrapper">
                        <div class = "carousel-slider">

                            <div class="video-container">
                                <video autoplay controls muted loop playsinline
                                    height="100%">
                                    <source
                                        src="./static/images/carousel_dynamics/dynamics_milk_3_small.mp4"
                                        type="video/mp4">
                                </video>
                            </div>

                            <div class="video-container">
                                <video autoplay controls muted loop playsinline
                                    height="100%">
                                    <source
                                        src="./static/images/carousel_dynamics/dynamics_oatly_11_small.mp4"
                                        type="video/mp4">
                                </video>
                            </div>

                            <div class="video-container">
                                <video autoplay controls muted loop playsinline
                                    height="100%">
                                    <source
                                        src="./static/images/carousel_dynamics/dynamics_styrofoam_1_small.mp4"
                                        type="video/mp4">
                                </video>
                            </div>

                            <div class="video-container">
                                <video autoplay controls muted loop playsinline
                                    height="100%">
                                    <source
                                        src="./static/images/carousel_dynamics/dynamics_egg_6_small.mp4"
                                        type="video/mp4">
                                </video>
                            </div>

                            <div class="video-container">
                                <video autoplay controls muted loop playsinline
                                    height="100%">
                                    <source
                                        src="./static/images/carousel_dynamics/dynamics_bottle_1_small.mp4"
                                        type="video/mp4">
                                </video>
                            </div>

                            <div class="video-container">
                                <video autoplay controls muted loop playsinline
                                    height="100%">
                                    <source
                                        src="./static/images/carousel_dynamics/dynamics_toblerone_11_small.mp4"
                                        type="video/mp4">
                                </video>
                            </div>

                            <div class="video-container">
                                <video autoplay controls muted loop playsinline
                                    height="100%">
                                    <source
                                        src="./static/images/carousel_dynamics/dynamics_bakingbox_3_small.mp4"
                                        type="video/mp4">
                                </video>
                            </div>

                            <div class="video-container">
                                <video autoplay controls muted loop playsinline
                                    height="100%">
                                    <source
                                        src="./static/images/carousel_dynamics/dynamics_milk_8_small.mp4"
                                        type="video/mp4">
                                </video>
                            </div>

                            <div class="video-container">
                                <video autoplay controls muted loop playsinline
                                    height="100%">
                                    <source
                                        src="./static/images/carousel_dynamics/dynamics_oatly_6_small.mp4"
                                        type="video/mp4">
                                </video>
                            </div>
                        </div>
                        <button class="carousel-button left" type="button">&lt;</button>
                        <button class="carousel-button right" type="button">&gt;</button>
                    </div>
                </nav>

                <p class="paragraph">
                    Because Vysics uses physics reasoning to inform the
                    recovered geometry, it enables accurate dynamics predictions
                    when predicting the original trajectory.  To do this, we
                    simulate the recorded robot commands in a simulator with the
                    learned object model, then we compare the resulting object
                    trajectory to the BundleSDF trajectory estimate.  The videos
                    above show the simulation results of Vysics models compared
                    to vision-only geometry (from BundleSDF), physics-only
                    geometry (from PLL), and the ground truth geometry (from a
                    3D scanner).
                </p>

                <img id="dynamics-img" src="./static/images/dynamics_cdf.png" />

                <p class="paragraph">
                    The plot above shows the average position and rotation
                    errors when predicting the entire length of the original
                    trajectory as an open-loop rollout, averaged for every
                    example and result in the dataset. The trajectories range in
                    length from 3 to 18 seconds.  We point out that even the
                    ground truth geometry baseline is imperfect, despite using
                    essentially perfect geometry, due to inaccurate modeling
                    assumptions such as object rigidity and the divergent nature
                    of the dynamics in many of our robot interactions.  Vysics
                    and PLL perform closely to this baseline, though Vysics is
                    moderately worse in orientation divergence.  While most of
                    the dynamics performance by PLL is retained in Vysics, it is
                    unsurprising to see a slight performance drop, given PLL
                    optimizes only for physics accuracy while Vysics balances
                    with visual objectives.  The vision-only baseline is the
                    least performant in both position and orientation rollout
                    accuracy.
                </p>
            </div>

            <br>

            <!-- Acknowledgments -->
            <div class="base-row add-top-padding">
                <h1 id="abstract">Acknowledgments</h1>

                <p class="paragraph">
                    We thank our anonymous reviewers, who provided thorough and
                    fair feedback that improved the quality of our paper.  This
                    work was supported by a National Defense Science and
                    Engineering Graduate (NDSEG) Fellowship, an NSF CAREER Award
                    under Grant No. FRR-2238480, and the RAI Institute.
                </p>
            </div>

            <br>

            <!-- Citation -->
            <div class="citation add-top-padding">
                <h1 id="abstract"> Citation </h1>
                <p> If you find this work useful, please consider citing: (bibtex) </p>
                <pre id="codecell0">@inproceedings{bianchini2025vysics,
&nbsp;title={Vysics: Object Reconstruction Under Occlusion by Fusing Vision and Contact-Rich Physics},
&nbsp;author={Bibit Bianchini and Minghan Zhu and Mengti Sun and Bowen Jiang and Camillo J. Taylor and Michael Posa},
&nbsp;year={2025},
&nbsp;month={june}, <!-- &nbsp;arxiv={TODO}, -->
&nbsp;booktitle={Robotics: Science and Systems (RSS)},
&nbsp;website={https://vysics-vision-and-physics.github.io/}, <!-- &nbsp;url={https://arxiv.org/abs/TODO} -->
}
</pre>
            </div>

            </div>
        </div>
    </div>

    		
    <p style="text-align:left;font-size:small;padding: 1%;">
        Source code for this page was taken from
        <a href="https://scenecomplete.github.io">SceneComplete's website</a>.
    </p>


    <script>
        document.querySelectorAll('.carousel-slider').forEach(
            (carousel, index) =>
        {
            const videoContainers = carousel.querySelectorAll(
                '.video-container');
            let currentPosition = 0;

            const leftButton = carousel.parentElement.querySelector(
                '.carousel-button.left');
            const rightButton = carousel.parentElement.querySelector(
                '.carousel-button.right');

            leftButton.addEventListener('click', () => {
                currentPosition = (currentPosition - 1 + videoContainers.length)
                    % videoContainers.length;
                carousel.scrollTo({
                    left: videoContainers[currentPosition].offsetLeft,
                    behavior: 'smooth'
                });
            });

            rightButton.addEventListener('click', () => {
                currentPosition = (currentPosition + 1)
                    % videoContainers.length;
                carousel.scrollTo({
                    left: videoContainers[currentPosition].offsetLeft,
                    behavior: 'smooth'
                });
            });
        });
    </script>
    <div hidden="hidden">
        <script type="text/javascript" id="clustrmaps"
            src="//clustrmaps.com/map_v2.js?d=Fp3OV0D2ycF0jHT6VcMi3CdJFG_vn6lt5jKJI4zhJYQ&cl=ffffff&w=a">
        </script>
    </div>
</body>
</html>
